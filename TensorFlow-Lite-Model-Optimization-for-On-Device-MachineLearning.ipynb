{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJwIonXEVJo6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow.keras.layers import Dropout, Dense, BatchNormalization\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbY-KGMPvbW9"
      },
      "outputs": [],
      "source": [
        "# Load Cat vs Dog dataset\n",
        "(train_ds, val_ds, test_ds), info = tfds.load('cats_vs_dogs', split=['train[:70%]', 'train[70%:90%]', 'train[90%:]'], shuffle_files=True, as_supervised=True, with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAN9xXvkBpE8"
      },
      "outputs": [],
      "source": [
        "print(\"Number of  Classes: \" + str(info.features['label'].num_classes))\n",
        "print(\"Classes : \" + str(info.features['label'].names))\n",
        "\n",
        "NUM_TRAIN_IMAGES = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "\n",
        "print(\"Training Images: \" + str(NUM_TRAIN_IMAGES))\n",
        "\n",
        "NUM_VAL_IMAGES = tf.data.experimental.cardinality(val_ds).numpy()\n",
        "\n",
        "print(\"Validation Images: \" + str(NUM_VAL_IMAGES))\n",
        "\n",
        "NUM_TEST_IMAGES = tf.data.experimental.cardinality(test_ds).numpy()\n",
        "\n",
        "print(\"Testing Images: \" + str(NUM_TEST_IMAGES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cssbGKwIvTI"
      },
      "outputs": [],
      "source": [
        "vis = tfds.visualization.show_examples(train_ds, info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm22cwrjJhkV"
      },
      "outputs": [],
      "source": [
        "# Defining Batch Size and input image size.\n",
        "batch_size = 16\n",
        "img_size = [224, 224]\n",
        "\n",
        "# Resizing images in dataset.\n",
        "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, img_size), y))\n",
        "val_ds = val_ds.map(lambda x, y: (tf.image.resize(x, img_size), y))\n",
        "test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, img_size), y))\n",
        "\n",
        "# Buffering the dataset.\n",
        "train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
        "val_ds = val_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
        "test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_P6TnvhrRyWt"
      },
      "outputs": [],
      "source": [
        "# Extracting and saving test images and labels from test dataset.\n",
        "test_images = []\n",
        "test_labels = []\n",
        "for image, label in test_ds.take(len(test_ds)).unbatch():\n",
        "  test_images.append(image)\n",
        "  test_labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_curYQ5AKbG"
      },
      "outputs": [],
      "source": [
        "# Defining the model architecture.\n",
        "resnet = tf.keras.applications.EfficientNetB0(include_top = False, weights ='imagenet', input_shape = (224, 224, 3), pooling = 'max')\n",
        "\n",
        "# Unfreezing all the layers of the model.\n",
        "for layer in resnet.layers:\n",
        "  set_trainable = True\n",
        "\n",
        "# Adding Dense, BatchNormalization, and Dropout layers to the base model.\n",
        "x = Dense(512, activation='relu')(resnet.output)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Define the input and output layers of the model.\n",
        "model = Model(inputs=resnet.input, outputs=predictions)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss =tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics = [\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnIcMwBpumu7"
      },
      "outputs": [],
      "source": [
        "# Defining file path.\n",
        "filepath = '/content/EfnetB0/model.h5'\n",
        "\n",
        "# Defining model Save Callback and Reduce Learning Rate Calllback for achieving better results.\n",
        "model_save = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath,\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode=\"max\",\n",
        "    save_freq=\"epoch\")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', \n",
        "                                                 factor=0.1, \n",
        "                                                 patience=3, \n",
        "                                                 verbose=1, \n",
        "                                                 min_delta=5*1e-3,\n",
        "                                                 min_lr =5*1e-9,)\n",
        "\n",
        "callback = [reduce_lr, model_save]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBJXtsSJAMNw"
      },
      "outputs": [],
      "source": [
        "# Training the model for 15 epochs.\n",
        "model.fit(train_ds, epochs=15, steps_per_epoch=(len(train_ds)//batch_size), validation_data=val_ds, validation_steps=(len(val_ds)//batch_size), shuffle=False, callbacks=callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyIKnbVZafIH"
      },
      "outputs": [],
      "source": [
        "# Evaluating the Model on test dataset.\n",
        "_, baseline_model_accuracy = model.evaluate(test_ds, verbose=0)\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo4JuX3Chvko"
      },
      "outputs": [],
      "source": [
        "model.save('/content/EfnetB0/efnetb0_saved_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_bUZBLs_q4N"
      },
      "outputs": [],
      "source": [
        "# Function for evaluating TFLite model over test images.\n",
        "def evaluate(interpreter):\n",
        "  prediction= []\n",
        "\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "  input_format = interpreter.get_output_details()[0]['dtype']\n",
        "  \n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 100 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(input_format)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.tensor(output_index)\n",
        "    predicted_label = np.argmax(output()[0])\n",
        "    prediction.append(predicted_label)\n",
        "    \n",
        "  print('\\n')\n",
        "  \n",
        "  # Comparing prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction = np.array(prediction)\n",
        "  accuracy = (prediction == test_labels).mean()\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg7E3Aa-dMZT"
      },
      "outputs": [],
      "source": [
        "# Passing Keras Model to TF Lite Converter.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Using float 16 quantization.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "# Converting the model \n",
        "tflite_fp16_model = converter.convert()\n",
        "\n",
        "# Saving the model.\n",
        "with open('/content/EfnetB0/fp_16_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_fp16_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3-KHpjyJwV8"
      },
      "outputs": [],
      "source": [
        "# Passing FP16 TFLite model to the interpreter\n",
        "interpreter = tf.lite.Interpreter('/content/EfnetB0/fp_16_model.tflite')\n",
        "# Allocating tensors.\n",
        "interpreter.allocate_tensors()\n",
        "# Evaluating the model on test dataset.\n",
        "test_accuracy = evaluate(interpreter)\n",
        "print('Float 16 Quantized TFLite Model Test Accuracy:', test_accuracy*100)\n",
        "print('Baseline Keras Model Test Accuracy:', baseline_model_accuracy*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7dV2wHKGfxp"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('/content/EfnetB0/model.h5')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HZ8cy4gebR_"
      },
      "outputs": [],
      "source": [
        "# Passing the baseline Keras model to TFLite converter.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Defining the representative dataset from training images.\n",
        "def representative_data_gen():\n",
        "  for input_value in tf.data.Dataset.from_tensor_slices(test_images).batch(1).take(100):\n",
        "    yield [input_value]\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "# Using integer quantization.\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "# Setting the input and output tensors to uint8 (APIs added in r2.3).\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "# Converting the model.\n",
        "int_quant_model = converter.convert()\n",
        "\n",
        "# Saving the integer quantized TFLite model.\n",
        "with open('/content/EfnetB0/int_quant_model.tflite', 'wb') as f:\n",
        "  f.write(int_quant_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51oTK0kYKxZw"
      },
      "outputs": [],
      "source": [
        "# Passing the integer quantized TFLitemodel to the interpreter.\n",
        "interpreter = tf.lite.Interpreter('/content/EfnetB0/int_quant_model.tflite')\n",
        "# Allocating tensors.\n",
        "interpreter.allocate_tensors()\n",
        "# Evaluating the model on test images.\n",
        "test_accuracy = evaluate(interpreter)\n",
        "print('Integer Quantized TFLite Model Test Accuracy:', test_accuracy*100)\n",
        "print('Baseline Keras Model Test Accuracy:', baseline_model_accuracy*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP7gag-fdR--"
      },
      "outputs": [],
      "source": [
        "# Passing baseline Keras model to TFLite converter.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "# Using Dynamic Range quantization.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# Converting the model.\n",
        "tflite_quant_model = converter.convert()\n",
        "# Saving the model.\n",
        "with open('/content/EfnetB0/dynamic_quant_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UnMpwhqLmqrF"
      },
      "outputs": [],
      "source": [
        "# Passing Dynamic Range quantized TFLite model to the interpreter.\n",
        "interpreter = tf.lite.Interpreter('/content/EfnetB0/dynamic_quant_model.tflite') \n",
        "# Allocating tensors.\n",
        "interpreter.allocate_tensors()\n",
        "# Evaluating the model on the test images.\n",
        "test_accuracy = evaluate(interpreter)\n",
        "print('Dynamically  Quantized TFLite Model Test Accuracy:', test_accuracy*100)\n",
        "print('Baseline Keras Model Test Accuracy:', baseline_model_accuracy*100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "TensorFlow Lite: Model Optimization for On-Device Machine Learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}